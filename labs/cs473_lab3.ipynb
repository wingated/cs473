{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPir_6bCCFnZ"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wingated/cs473/blob/main/labs/cs473_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><p><b>After clicking the \"Open in Colab\" link, copy the notebook to your own Google Drive before getting started, or it will not save your work</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_slaQdUGCB0t"
   },
   "source": [
    "# BYU CS 473 Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ct7fnkcnCL8O"
   },
   "source": [
    "## Introduction:\n",
    "KL divergence is one of the most commonly used concepts in machine learning. Here, we'll explore the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUat5xRAcdrC"
   },
   "source": [
    "---\n",
    "## Exercise #1: Symmetry    \n",
    "\n",
    "KL divergence is a *measure*, but not a *metric*. This means that while it satisfies some properties of things like a distance metric, it does not satisfy all of them.\n",
    "\n",
    "For example, KL divergence is NOT symmetric. First, implement a function that calculates the KL divergence between two discrete distributions. Then,cCraft an example to demonstrate that it is not symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1m2KIHShNdC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kl(a,b):\n",
    "    # a is a n-dimensional distribution\n",
    "    # b is a n-dimensional distribution\n",
    "    #\n",
    "    # return: KL(a||b)\n",
    "\n",
    "    # your code here\n",
    "    pass\n",
    "\n",
    "# find an example where kl(a,b) != kl(b,a)\n",
    "a = [ ]\n",
    "b = [ ]\n",
    "# etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise #2: Triangle inequality\n",
    "\n",
    "Another property that KL divergence does not satisfy is the triangle inequality, which states that\n",
    "\n",
    "kl(a,c) >= kl(a,b)+kl(b,c)\n",
    "\n",
    "Prove that KL divergence does not satisfy the triangle inequality by crafting a counter-example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "c = []\n",
    "# etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise #3: Proofs\n",
    "\n",
    "Prove that:\n",
    "\n",
    "1) kl(a,a) = 0\n",
    "2) kl(a,b) >= 0\n",
    "\n",
    "Extra credit:\n",
    "\n",
    "3) kl(a,b) = 0 iff a==b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
